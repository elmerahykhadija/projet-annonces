# ğŸ›’ Marketplace Aggregator - Projet Annonces

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Kafka](https://img.shields.io/badge/Apache%20Kafka-Latest-black.svg)
![Spark](https://img.shields.io/badge/Apache%20Spark-3.5.0-orange.svg)
![MySQL](https://img.shields.io/badge/MySQL-8.0-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)

## ğŸ“‹ Description

**Marketplace Aggregator** est une application de scraping et d'agrÃ©gation d'annonces en temps rÃ©el provenant de plusieurs plateformes marocaines (Avito, MarocAnnonces). Le systÃ¨me collecte, traite via Apache Spark Streaming et affiche les donnÃ©es dans une interface web moderne avec dashboard analytique.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SOURCES DE DONNÃ‰ES                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   Avito.ma   â”‚              â”‚MarocAnnonces â”‚                 â”‚
â”‚  â”‚   (GraphQL)  â”‚              â”‚    (HTML)    â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COUCHE D'EXTRACTION (Scraping)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ producer1.py â”‚              â”‚producer2.py  â”‚                 â”‚
â”‚  â”‚ Scrape Avito â”‚              â”‚Scrape MA     â”‚                 â”‚
â”‚  â”‚ (60s cycle)  â”‚              â”‚ (30s cycle)  â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MESSAGE BROKER (Kafka)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Topic: avito_listings â”‚    â”‚Topic: annonces-rawâ”‚             â”‚
â”‚  â”‚    (Producer1)      â”‚    â”‚    (Producer2)     â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                         â”‚
             â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           STREAM PROCESSING (Apache Spark)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚spark_job1.py â”‚              â”‚spark_job2.py â”‚                 â”‚
â”‚  â”‚Process Avito â”‚              â”‚  Process MA  â”‚                 â”‚
â”‚  â”‚(10s batch)   â”‚              â”‚ (10s batch)  â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 STOCKAGE (MySQL 8.0)                             â”‚
â”‚         Database: avito_db | Port: 3307                          â”‚
â”‚              Table: annonces                                     â”‚
â”‚      Deduplication basÃ©e sur URL                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              APPLICATION LAYER (Streamlit)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   app.py     â”‚              â”‚dashboard.py  â”‚                 â”‚
â”‚  â”‚ (Main UI)    â”‚              â”‚ (Analytics)  â”‚                 â”‚
â”‚  â”‚  Cache: 30s  â”‚              â”‚Auto-refresh:5sâ”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   UTILISATEURS FINAUX                            â”‚
â”‚                    (Web Browser)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Technologies UtilisÃ©es

- **Backend**
  - Python 3.9+
  - Apache Kafka (Message Broker)
  - Apache Spark 3.5.0 (Stream Processing)
  - MySQL 8.0 (Base de donnÃ©es - Port 3307)
  - Requests + BeautifulSoup4 (Scraping)

- **Frontend**
  - Streamlit (Interface web)
  - Plotly (Graphiques interactifs)
  - Pandas (Manipulation de donnÃ©es)

## ğŸ“¦ PrÃ©requis

- Python 3.9 ou supÃ©rieur
- Java 11+ (pour Spark)
- MySQL Server (port 3307)
- Apache Kafka + Zookeeper
- Apache Spark 3.5.0
- Connexion Internet (pour le scraping)

## âš™ï¸ Installation

### 1. Cloner le projet

```bash
git clone https://github.com/votre-username/projet-annonces.git
cd projet-annonces
```

### 2. CrÃ©er un environnement virtuel

```bash
python -m venv venv
venv\Scripts\activate  # Sur Windows
# source venv/bin/activate  # Sur Linux/Mac
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

**Contenu de `requirements.txt` :**
```txt
streamlit==1.28.0
pandas==2.1.0
mysql-connector-python==8.1.0
kafka-python==2.0.2
requests==2.31.0
beautifulsoup4==4.12.2
plotly==5.17.0
pyspark==3.5.0
```

### 4. Configuration de la base de donnÃ©es

```sql
CREATE DATABASE avito_db;

USE avito_db;

CREATE TABLE annonces (
    id INT AUTO_INCREMENT PRIMARY KEY,
    source VARCHAR(50),
    category VARCHAR(100),
    sous_categorie VARCHAR(100),
    titre TEXT,
    prix VARCHAR(50),
    localisation VARCHAR(100),
    url TEXT UNIQUE,
    image_url TEXT,
    date_text VARCHAR(100),
    timestamp_scraped BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_source (source),
    INDEX idx_category (category),
    INDEX idx_url (url(255)),
    INDEX idx_timestamp (timestamp_scraped)
);
```

### 5. DÃ©marrer Kafka et Zookeeper

**Sous Windows :**
```bash
# Terminal 1 - Zookeeper
cd C:\kafka
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties

# Terminal 2 - Kafka
.\bin\windows\kafka-server-start.bat .\config\server.properties
```

### 6. CrÃ©er les topics Kafka

```bash
# Topic pour Avito
.\bin\windows\kafka-topics.bat --create --topic avito_listings --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

# Topic pour MarocAnnonces
.\bin\windows\kafka-topics.bat --create --topic annonces-raw --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
```

## ğŸ® Utilisation

### Architecture de DÃ©marrage

**âš ï¸ IMPORTANT : Les Spark Jobs lancent automatiquement les Producers !**

Vous n'avez besoin que de **2 terminaux Spark + 2 terminaux Streamlit**.

### 1. Lancer Spark Job 1 (Avito) - Lance automatiquement producer1.py

```bash
python spark_job1.py
```
Ce script va :
- âœ… DÃ©marrer `producer1.py` (scraping Avito toutes les 60s)
- âœ… Consommer le topic `avito_listings`
- âœ… Traiter les donnÃ©es avec Spark Streaming
- âœ… InsÃ©rer dans MySQL avec deduplication

### 2. Lancer Spark Job 2 (MarocAnnonces) - Lance automatiquement producer2.py

```bash
python spark_job2.py
```
Ce script va :
- âœ… DÃ©marrer `producer2.py` (scraping MarocAnnonces toutes les 30s)
- âœ… Consommer le topic `annonces-raw`
- âœ… Traiter les donnÃ©es avec Spark Streaming
- âœ… InsÃ©rer dans MySQL avec deduplication

### 3. Lancer l'application Streamlit principale

```bash
streamlit run app.py
```

Interface accessible sur : `http://localhost:8501`

### 4. Lancer le Dashboard Analytics

```bash
streamlit run dashboard.py
```

Dashboard accessible sur : `http://localhost:8502`

## ğŸ“ Structure du Projet

```
projet-annonces/
â”‚
â”œâ”€â”€ producer1.py           # Producer Kafka pour Avito (API GraphQL)
â”œâ”€â”€ producer2.py           # Producer Kafka pour MarocAnnonces (HTML)
â”œâ”€â”€ spark_job1.py          # Spark Streaming Job pour Avito (lance producer1)
â”œâ”€â”€ spark_job2.py          # Spark Streaming Job pour MarocAnnonces (lance producer2)
â”œâ”€â”€ app.py                 # Application principale Streamlit
â”œâ”€â”€ dashboard.py           # Dashboard analytique avec auto-refresh (5s)
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”œâ”€â”€ checkpoint_avito/      # Checkpoints Spark Job 1 (gÃ©nÃ©rÃ© auto)
â”œâ”€â”€ checkpoint_marocannonces/  # Checkpoints Spark Job 2 (gÃ©nÃ©rÃ© auto)
â””â”€â”€ README.md             # Documentation
```

## âœ¨ FonctionnalitÃ©s

### Producer 1 (Avito)
- âœ… Scraping via API GraphQL officielle
- âœ… Cycle : 60 secondes
- âœ… Gestion du cache (Ã©vite doublons en mÃ©moire)
- âœ… Extraction :
  - Titre, Prix, CatÃ©gorie
  - Localisation (Ville)
  - Images
  - URL unique

### Producer 2 (MarocAnnonces)
- âœ… Scraping HTML avec BeautifulSoup4
- âœ… Cycle : 30 secondes
- âœ… Filtre : **DerniÃ¨res 72 heures** (3 jours)
- âœ… CatÃ©gories : Auto-Moto, Immobilier, MultimÃ©dia
- âœ… DÃ©tection des doublons avant envoi

### Spark Jobs
- âœ… **Lancement automatique** des producers
- âœ… Stream Processing (micro-batching : 10 secondes)
- âœ… **Deduplication MySQL** avant insertion (basÃ©e sur URL)
- âœ… Compteurs par catÃ©gorie
- âœ… Gestion des erreurs et logging

### Application Principale (app.py)
- âœ… Affichage en **grille 3 colonnes**
- âœ… **Filtres avancÃ©s** :
  - ğŸ“‚ CatÃ©gorie
  - ğŸ“ Ville
  - ğŸŒ Source (Avito / MarocAnnonces)
  - ğŸ’° **Budget maximum (saisie manuelle)**
  - ğŸ” Recherche par mot-clÃ©
- âœ… Cache intelligent (TTL 30s)
- âœ… Design moderne avec CSS personnalisÃ©
- âœ… Badges colorÃ©s par source

### Dashboard Analytics (dashboard.py)
- âœ… **Auto-refresh : 5 secondes**
- âœ… **KPIs en temps rÃ©el** :
  - Total d'annonces
  - Prix moyen
  - Nombre de villes
  - DerniÃ¨re mise Ã  jour (HH:MM:SS)
- âœ… **Graphiques interactifs** :
  - ğŸ¥§ RÃ©partition par source (Pie Chart)
  - ğŸ“Š Top catÃ©gories (Bar Chart)
  - ğŸ“¦ Distribution des prix (Boxplot)
- âœ… Tableau des 50 derniÃ¨res annonces

## ğŸ”§ Configuration

### Modifier les intervalles de scraping

**producer1.py (Avito) :**
```python
# Ligne 170
time.sleep(60)  # Modifier l'intervalle (en secondes)
```

**producer2.py (MarocAnnonces) :**
```python
# Ligne 199
producer.run_continuous(interval_seconds=30)  # Modifier ici
```

### Modifier la pÃ©riode de scraping (72h)

**producer2.py :**
```python
# Ligne 54
scrape_days = 3  # Changer le nombre de jours
```

### Modifier l'auto-refresh du dashboard

**dashboard.py :**
```python
# Ligne 33
@st.cache_data(ttl=5)  # Modifier le TTL du cache

# Ligne 108
time.sleep(5)  # Modifier l'intervalle de refresh
```

### Modifier le batch Spark

**spark_job1.py et spark_job2.py :**
```python
# DerniÃ¨re ligne avant .start()
.trigger(processingTime='10 seconds')  # Modifier ici
```

## ğŸ“Š Flux de DonnÃ©es

```
1. Producer scrape les sites web (60s pour Avito, 30s pour MA)
2. Envoi des messages JSON vers Kafka
3. Spark Streaming consomme les topics
4. Traitement : parsing + deduplication
5. Insertion dans MySQL (table annonces)
6. Streamlit lit MySQL et affiche les donnÃ©es
```

## ğŸ› RÃ©solution de ProblÃ¨mes

### Erreur : "No module named 'pyspark'"
```bash
pip install pyspark==3.5.0
```

### Erreur : Spark ne trouve pas Java
```bash
# Installer Java 11+
# Windows : TÃ©lÃ©charger depuis Oracle
# VÃ©rifier :
java -version
```

### Erreur : Connexion MySQL refusÃ©e
```bash
# VÃ©rifier que MySQL tourne sur le port 3307
mysql -u user -p -P 3307 -h localhost
```

### Erreur : Kafka n'est pas accessible
```bash
# VÃ©rifier Zookeeper et Kafka
# Tester la connexion
telnet localhost 9092
```

### Les Spark Jobs ne dÃ©marrent pas les producers
VÃ©rifiez que `producer1.py` et `producer2.py` sont dans le mÃªme dossier que les spark_jobs.

### Les annonces ne s'affichent pas dans Streamlit
1. VÃ©rifiez que les Spark Jobs tournent
2. VÃ©rifiez que les donnÃ©es arrivent dans MySQL :
```sql
SELECT COUNT(*), source FROM annonces GROUP BY source;
```

## ğŸ“ˆ Monitoring

### VÃ©rifier les topics Kafka
```bash
# Liste des topics
.\bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092

# Messages dans un topic
.\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic avito_listings --from-beginning
```

### VÃ©rifier MySQL
```sql
-- Nombre total d'annonces
SELECT COUNT(*) FROM annonces;

-- Par source
SELECT source, COUNT(*) FROM annonces GROUP BY source;

-- DerniÃ¨res annonces
SELECT titre, prix, source, FROM_UNIXTIME(timestamp_scraped) 
FROM annonces 
ORDER BY timestamp_scraped DESC 
LIMIT 10;
```

## ğŸ¤ Contributions

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le projet
2. CrÃ©ez une branche (`git checkout -b feature/amelioration`)
3. Committez vos changements (`git commit -m 'Ajout fonctionnalitÃ© X'`)
4. Pushez vers la branche (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

## ğŸ“ Licence

Ce projet est sous licence MIT.

## ğŸ‘¤ Auteur

**Elmer**
- Projet : Marketplace Aggregator
- Date : DÃ©cembre 2024

## ğŸ“§ Contact

Pour toute question :
- Email: votre.email@example.com
- GitHub: [@votre-username](https://github.com/votre-username)

---

## ğŸ¯ SpÃ©cifications Techniques

### Infrastructure
- **OS**: Windows 10/11
- **Python**: 3.9+
- **Kafka**: 3.5.0
- **Spark**: 3.5.0
- **MySQL**: 8.0 (Port 3307)

### Performance
- **Producer1 (Avito)**: ~50-100 annonces/minute
- **Producer2 (MA)**: ~20-50 annonces/minute
- **Spark Streaming**: Batch 10 secondes
- **Latence Kafka**: < 100ms
- **Deduplication**: BasÃ©e sur URL (UNIQUE constraint)

### Volumes
- **Annonces totales**: ~500-1000/jour
- **Taille DB**: ~50MB
- **Throughput Kafka**: ~5-10 messages/seconde

---

â­ **Si ce projet vous a Ã©tÃ© utile, n'oubliez pas de mettre une Ã©toile !**
