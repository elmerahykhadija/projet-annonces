# ğŸ›’ Marketplace - Projet Annonces

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Kafka](https://img.shields.io/badge/Apache%20Kafka-Latest-black.svg)
![MySQL](https://img.shields.io/badge/MySQL-8.0-orange.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)

## ğŸ“‹ Description

**Marketplace Aggregator** est une application de scraping et d'agrÃ©gation d'annonces en temps rÃ©el provenant de plusieurs plateformes marocaines (Avito, MarocAnnonces). Le systÃ¨me collecte, traite et affiche les donnÃ©es dans une interface web moderne avec dashboard analytique.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Avito     â”‚â”€â”€â”€â”€â–¶â”‚  Producer1  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚MarocAnnoncesâ”‚â”€â”€â”€â”€â–¶â”‚  Producer2  â”‚â”€â”€â”€â”€â–¶â”‚  Kafka   â”‚â”€â”€â”€â”€â–¶â”‚ Consumer â”‚â”€â”€â”€â”€â–¶â”‚  MySQL   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                                                                 â”‚
                                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                          â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚   Streamlit App    â”‚
                                               â”‚  (app.py + dash)   â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Technologies UtilisÃ©es

- **Backend**
  - Python 3.9+
  - Apache Kafka (Streaming)
  - MySQL 8.0 (Base de donnÃ©es)
  - Requests + BeautifulSoup4 (Scraping)

- **Frontend**
  - Streamlit (Interface web)
  - Plotly (Graphiques interactifs)
  - Pandas (Manipulation de donnÃ©es)

## ğŸ“¦ PrÃ©requis

- Python 3.9 ou supÃ©rieur
- MySQL Server (port 3307)
- Apache Kafka + Zookeeper
- Connexion Internet (pour le scraping)

## âš™ï¸ Installation

### 1. Cloner le projet

```bash
git clone https://github.com/votre-username/projet-annonces.git
cd projet-annonces
```

### 2. CrÃ©er un environnement virtuel

```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

**Contenu de `requirements.txt` :**
```txt
streamlit==1.28.0
pandas==2.1.0
mysql-connector-python==8.1.0
kafka-python==2.0.2
requests==2.31.0
beautifulsoup4==4.12.2
plotly==5.17.0
```

### 4. Configuration de la base de donnÃ©es

```sql
CREATE DATABASE avito_db;

USE avito_db;

CREATE TABLE annonces (
    id INT AUTO_INCREMENT PRIMARY KEY,
    source VARCHAR(50),
    category VARCHAR(100),
    titre TEXT,
    prix VARCHAR(50),
    localisation VARCHAR(100),
    url TEXT,
    image_url TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_source (source),
    INDEX idx_category (category),
    INDEX idx_created_at (created_at)
);
```

### 5. DÃ©marrer Kafka et Zookeeper

**Sous Windows :**
```bash
# Terminal 1 - Zookeeper
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties

# Terminal 2 - Kafka
.\bin\windows\kafka-server-start.bat .\config\server.properties
```

**Sous Linux/Mac :**
```bash
# Terminal 1 - Zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties

# Terminal 2 - Kafka
bin/kafka-server-start.sh config/server.properties
```

### 6. CrÃ©er le topic Kafka

```bash
# Windows
.\bin\windows\kafka-topics.bat --create --topic annonces-raw --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

# Linux/Mac
bin/kafka-topics.sh --create --topic annonces-raw --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
```

## ğŸ® Utilisation

### 1. DÃ©marrer le Consumer (Base de donnÃ©es)

```bash
python consumer.py
```

### 2. Lancer les Producers (Scraping)

**Terminal 1 - Producer Avito :**
```bash
python producer.py
```

**Terminal 2 - Producer MarocAnnonces :**
```bash
python producer2.py
```

### 3. Lancer l'application Streamlit

**Interface principale :**
```bash
streamlit run app.py
```

**Dashboard Analytics :**
```bash
streamlit run dashboard.py
```

## ğŸ“ Structure du Projet

```
projet-annonces/
â”‚
â”œâ”€â”€ app.py                 # Application principale Streamlit
â”œâ”€â”€ dashboard.py           # Dashboard analytique avec auto-refresh (5s)
â”œâ”€â”€ producer.py            # Producer Kafka pour Avito
â”œâ”€â”€ producer2.py           # Producer Kafka pour MarocAnnonces
â”œâ”€â”€ consumer.py            # Consumer Kafka â†’ MySQL
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â””â”€â”€ README.md             # Documentation
```

## âœ¨ FonctionnalitÃ©s

### Application Principale (app.py)
- âœ… Affichage en grille de 3 colonnes
- âœ… Filtres avancÃ©s :
  - CatÃ©gorie
  - Ville
  - Source (Avito / MarocAnnonces)
  - Budget maximum
  - Recherche par mot-clÃ©
- âœ… Cache intelligent (TTL 30s)
- âœ… Design responsive avec CSS personnalisÃ©

### Dashboard Analytics (dashboard.py)
- âœ… Auto-refresh toutes les 5 secondes
- âœ… KPIs en temps rÃ©el :
  - Total d'annonces
  - Prix moyen
  - Nombre de villes
  - DerniÃ¨re mise Ã  jour
- âœ… Graphiques interactifs :
  - RÃ©partition par source (Pie Chart)
  - Top catÃ©gories (Bar Chart)
  - Distribution des prix (Boxplot)
- âœ… Tableau des donnÃ©es brutes

### Producers
- âœ… Scraping automatique toutes les 30 secondes
- âœ… Filtrage des annonces des 72 derniÃ¨res heures
- âœ… DÃ©tection des doublons
- âœ… Gestion des erreurs et retry automatique

### Consumer
- âœ… Insertion en base de donnÃ©es en temps rÃ©el
- âœ… DÃ©tection des doublons (basÃ©e sur l'URL)
- âœ… Transactions MySQL optimisÃ©es

## ğŸ”§ Configuration

### Modifier les paramÃ¨tres de scraping

**producer.py / producer2.py :**
```python
# Intervalle de scraping (en secondes)
producer.run_continuous(interval_seconds=30)

# PÃ©riode de scraping (en jours)
scrape_days = 3  # 72 heures
```

### Modifier l'auto-refresh du dashboard

**dashboard.py :**
```python
@st.cache_data(ttl=5)  # Modifier le TTL (en secondes)

# Ligne 108
time.sleep(5)  # Modifier l'intervalle de refresh
```

## ğŸ“Š Exemples de DonnÃ©es

**Format des annonces collectÃ©es :**
```json
{
  "source": "avito",
  "category": "Auto-Moto",
  "titre": "Dacia Logan 2015 - Essence",
  "prix": "65 000 DH",
  "localisation": "Casablanca",
  "url": "https://www.avito.ma/...",
  "image_url": "https://...",
  "created_at": "2024-12-11 21:43:52"
}
```

## ğŸ› RÃ©solution de ProblÃ¨mes

### Erreur : "No module named 'streamlit'"
```bash
pip install streamlit
```

### Erreur : Connexion MySQL refusÃ©e
VÃ©rifiez que MySQL tourne sur le port 3307 :
```bash
mysql -u user -p -P 3307 -h localhost
```

### Erreur : Kafka n'est pas accessible
Assurez-vous que Zookeeper et Kafka sont dÃ©marrÃ©s :
```bash
# Tester la connexion
telnet localhost 9092
```

### Les annonces ne s'affichent pas
1. VÃ©rifiez que les producers tournent
2. VÃ©rifiez que le consumer insÃ¨re les donnÃ©es :
```sql
SELECT COUNT(*) FROM annonces;
```

## ğŸ¤ Contributions

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le projet
2. CrÃ©ez une branche (`git checkout -b feature/amelioration`)
3. Committez vos changements (`git commit -m 'Ajout fonctionnalitÃ© X'`)
4. Pushez vers la branche (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ‘¤ Auteur

**Elmer**
- Projet : Marketplace Aggregator
- Date : DÃ©cembre 2024

## ğŸ“§ Contact

Pour toute question ou suggestion :
- Email : votre.email@example.com
- GitHub : [@votre-username](https://github.com/votre-username)

---

â­ **Si ce projet vous a Ã©tÃ© utile, n'oubliez pas de mettre une Ã©toile !**